{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1122723,
          "sourceType": "datasetVersion",
          "datasetId": 630856
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset by Kagglehub"
      ],
      "metadata": {
        "id": "707r8KaVVySW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"karakaggle/kaggle-cat-vs-dog-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxtY0QCvD2dX",
        "outputId": "8ed3d1a8-cd01-4da4-92fb-01cbdf7f48ce",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/karakaggle/kaggle-cat-vs-dog-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 787M/787M [00:33<00:00, 24.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/karakaggle/kaggle-cat-vs-dog-dataset/versions/1\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation and Splitting"
      ],
      "metadata": {
        "id": "w7QtrGy7VySb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from PIL import UnidentifiedImageError\n",
        "\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 5\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.2\n",
        "\n",
        "DATASET_PATH = os.path.join(path, 'kagglecatsanddogs_3367a', 'PetImages')\n",
        "SPLIT_DATASET_PATH = \"PetImages_Split\"\n",
        "CLASSES = [\"Cat\", \"Dog\"]\n",
        "\n",
        "# Function to clean and split the dataset\n",
        "def clean_and_split_dataset(dataset_path, output_path, train_ratio=0.7, val_ratio=0.2):\n",
        "    # Create train/val/test directories\n",
        "    for subset in [\"train\", \"val\", \"test\"]:\n",
        "        for cls in CLASSES:\n",
        "            os.makedirs(os.path.join(output_path, subset, cls), exist_ok=True)\n",
        "\n",
        "    # Process and split each class\n",
        "    for cls in CLASSES:\n",
        "        cls_path = os.path.join(dataset_path, cls)\n",
        "        images = [f for f in os.listdir(cls_path) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "        # Check and clean corrupt images\n",
        "        valid_images = []\n",
        "        for img in images:\n",
        "            img_path = os.path.join(cls_path, img)\n",
        "            try:\n",
        "                tf.keras.preprocessing.image.load_img(img_path).close()\n",
        "                valid_images.append(img)\n",
        "            except (UnidentifiedImageError, OSError):\n",
        "                os.remove(img_path)\n",
        "                print(f\"Removed corrupt image: {img_path}\")\n",
        "\n",
        "        # Split into train, val, and test\n",
        "        train, temp = train_test_split(valid_images, train_size=train_ratio, random_state=42)\n",
        "        val, test = train_test_split(temp, test_size=(1 - train_ratio - val_ratio) / (1 - train_ratio), random_state=42)\n",
        "\n",
        "        # Move files into respective folders\n",
        "        for subset, split in zip([\"train\", \"val\", \"test\"], [train, val, test]):\n",
        "            for img in split:\n",
        "                src = os.path.join(cls_path, img)\n",
        "                dst = os.path.join(output_path, subset, cls, img)\n",
        "                shutil.copy(src, dst)\n",
        "\n",
        "    print(\"Dataset cleaned and split into train/val/test subsets.\")\n",
        "\n",
        "# Clean and split the dataset\n",
        "clean_and_split_dataset(DATASET_PATH, SPLIT_DATASET_PATH)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2II-p_2fSequ",
        "outputId": "27f3f39a-8a61-4a81-d4c6-553afefe2057",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset cleaned and split into train/val/test subsets.\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Augmentation"
      ],
      "metadata": {
        "id": "RDh_dv_xVySe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data generators\n",
        "data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Training and validation datasets\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    os.path.join(SPLIT_DATASET_PATH, \"train\"),\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\"\n",
        ")\n",
        "\n",
        "validation_generator = data_gen.flow_from_directory(\n",
        "    os.path.join(SPLIT_DATASET_PATH, \"val\"),\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\"\n",
        ")\n",
        "\n",
        "# Test dataset\n",
        "test_generator = data_gen.flow_from_directory(\n",
        "    os.path.join(SPLIT_DATASET_PATH, \"test\"),\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\"\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "342R3c3AVySe",
        "outputId": "eb288ceb-384d-4f9c-f1f3-2f6787a9f4a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 17471 images belonging to 2 classes.\n",
            "Found 4990 images belonging to 2 classes.\n",
            "Found 2498 images belonging to 2 classes.\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Base Model (MobileNet) on \"Cat vs Dog\" dataset and checking results\n",
        "\n",
        "In this step, we define a MobileNet-based CNN architecture from scratch (no pre-trained weights), compile it with the Adam optimizer, and train it on the Cat vs Dog dataset.\n",
        "After training, we evaluate the model on the test set to check its performance in terms of loss and accuracy."
      ],
      "metadata": {
        "id": "3WmsXlnjhNtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create MobileNet model for retraining\n",
        "def create_model():\n",
        "    # Initialize MobileNet with random weights\n",
        "    base_mobilenet = tf.keras.applications.MobileNet(\n",
        "        input_shape=(*IMAGE_SIZE, 3),\n",
        "        include_top=False,\n",
        "        # No pre-trained weights\n",
        "        weights=None\n",
        "    )\n",
        "    model = Sequential([\n",
        "        base_mobilenet,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dropout(0.5),\n",
        "        # Binary classification output\n",
        "        Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile and train model\n",
        "model = create_model()\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"Retraining the MobileNet model from scratch...\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"Validation Loss: {loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooj9YFKyEtUH",
        "outputId": "a33fb085-fbba-4e74-b09c-e3b9389e4baa",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retraining the MobileNet model from scratch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 767ms/step - accuracy: 0.5826 - loss: 0.7050 - val_accuracy: 0.4996 - val_loss: 0.6932\n",
            "Epoch 2/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 455ms/step - accuracy: 0.6647 - loss: 0.6172 - val_accuracy: 0.4996 - val_loss: 0.7057\n",
            "Epoch 3/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 448ms/step - accuracy: 0.7299 - loss: 0.5296 - val_accuracy: 0.4996 - val_loss: 0.7008\n",
            "Epoch 4/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 452ms/step - accuracy: 0.7850 - loss: 0.4528 - val_accuracy: 0.5004 - val_loss: 0.8302\n",
            "Epoch 5/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 453ms/step - accuracy: 0.8225 - loss: 0.3924 - val_accuracy: 0.7541 - val_loss: 0.4955\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 798ms/step - accuracy: 0.7518 - loss: 0.5012\n",
            "Validation Loss: 0.5045\n",
            "Validation Accuracy: 0.7478\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with MobileNet\n",
        "\n",
        "In this step, we use MobileNet pre-trained on ImageNet as the base model and freeze its layers.\n",
        "We then add custom classification layers on top and train only those layers on our Cat vs Dog dataset.\n",
        "\n",
        "Finally, we evaluate the model on the test set to check its accuracy and loss."
      ],
      "metadata": {
        "id": "Gd2VF3Gfhbjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "\n",
        "def create_transfer_learning_model():\n",
        "    # Load the MobileNet base model\n",
        "    base_mobilenet = MobileNet(input_shape=(*IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
        "    # Freeze the base layers\n",
        "    base_mobilenet.trainable = False\n",
        "\n",
        "    # Create a new model by adding custom layers on top of the pre-trained base\n",
        "    model = Sequential([\n",
        "        base_mobilenet,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dropout(0.5),\n",
        "        # Output layer for binary classification\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile and train transfer learning model\n",
        "transfer_learning_model = create_transfer_learning_model()\n",
        "transfer_learning_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training Transfer Learning Model (MobileNet with ImageNet weights)...\")\n",
        "history_transfer = transfer_learning_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=5\n",
        ")\n",
        "\n",
        "\n",
        "transfer_learning_model.save('transfer_learning_mobilenet_model.keras')\n",
        "\n",
        "#MODEL EVALUATION\n",
        "\n",
        "transfer_learning_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "loss, accuracy = transfer_learning_model.evaluate(test_generator)\n",
        "\n",
        "\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tVIJkSdHiRw",
        "outputId": "9e3a15a6-9a42-4893-a725-749c550f1b22",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "\u001b[1m17225924/17225924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Training Transfer Learning Model (MobileNet with ImageNet weights)...\n",
            "Epoch 1/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 460ms/step - accuracy: 0.7709 - loss: 0.4673 - val_accuracy: 0.9772 - val_loss: 0.0676\n",
            "Epoch 2/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 401ms/step - accuracy: 0.9680 - loss: 0.0898 - val_accuracy: 0.9828 - val_loss: 0.0502\n",
            "Epoch 3/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 395ms/step - accuracy: 0.9747 - loss: 0.0656 - val_accuracy: 0.9840 - val_loss: 0.0433\n",
            "Epoch 4/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 460ms/step - accuracy: 0.9785 - loss: 0.0621 - val_accuracy: 0.9842 - val_loss: 0.0402\n",
            "Epoch 5/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 396ms/step - accuracy: 0.9792 - loss: 0.0557 - val_accuracy: 0.9842 - val_loss: 0.0380\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 401ms/step - accuracy: 0.9849 - loss: 0.0444\n",
            "Test Loss: 0.0449\n",
            "Test Accuracy: 0.9864\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluating Different CNN Models**\n",
        "## Here we train and evaluate four popular CNN architectures on the Cat vs Dog dataset to compare performance:\n",
        "## 1. LeNet\n",
        "## 2. AlexNet\n",
        "## 3. VGGNet\n",
        "## 4. ResNet"
      ],
      "metadata": {
        "id": "xCLaK-pnVySh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. LeNet Model\n",
        "We implement the LeNet architecture, one of the earliest CNNs, and train it on the Cat vs Dog dataset.\n",
        "After training, we evaluate its performance on the test set."
      ],
      "metadata": {
        "id": "bip1iDW1VySh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##---------LeNet Model--------##\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "def create_lenet_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(*IMAGE_SIZE, 3)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(120, activation='relu'),\n",
        "        Dense(84, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "lenet_model = create_lenet_model()\n",
        "lenet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training LeNet Model...\")\n",
        "lenet_history = lenet_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "lenet_model.save('lenet_model.keras')\n",
        "\n",
        "# Evaluate LeNet model\n",
        "lenet_loss, lenet_accuracy = lenet_model.evaluate(test_generator)\n",
        "print(f\"LeNet Test Loss: {lenet_loss:.4f}\")\n",
        "print(f\"LeNet Test Accuracy: {lenet_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "xz7KqrPPieF-",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef1cf29-5a67-42e5-c25c-bf990cf0a23d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LeNet Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 476ms/step - accuracy: 0.5860 - loss: 0.6772 - val_accuracy: 0.7295 - val_loss: 0.5338\n",
            "Epoch 2/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 387ms/step - accuracy: 0.7796 - loss: 0.4709 - val_accuracy: 0.7613 - val_loss: 0.4954\n",
            "Epoch 3/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 398ms/step - accuracy: 0.8463 - loss: 0.3486 - val_accuracy: 0.7641 - val_loss: 0.5175\n",
            "Epoch 4/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 388ms/step - accuracy: 0.9045 - loss: 0.2351 - val_accuracy: 0.7659 - val_loss: 0.6016\n",
            "Epoch 5/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 388ms/step - accuracy: 0.9607 - loss: 0.1188 - val_accuracy: 0.7487 - val_loss: 0.7516\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 358ms/step - accuracy: 0.7468 - loss: 0.8244\n",
            "LeNet Test Loss: 0.7846\n",
            "LeNet Test Accuracy: 0.7526\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. AlexNet Model\n",
        "\n",
        "We implement the AlexNet architecture, a deeper CNN that popularized deep learning in computer vision.\n",
        "The model is trained on the Cat vs Dog dataset and evaluated on the test set."
      ],
      "metadata": {
        "id": "a7-lrLxkVySh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##------------------AlexNet Model------------##\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "def create_alexnet_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(96, kernel_size=(11, 11), strides=4, activation='relu', input_shape=(*IMAGE_SIZE, 3)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(3, 3), strides=2),\n",
        "        Conv2D(256, kernel_size=(5, 5), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(3, 3), strides=2),\n",
        "        Conv2D(384, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(384, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(3, 3), strides=2),\n",
        "        Flatten(),\n",
        "        Dense(4096, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(4096, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "alexnet_model = create_alexnet_model()\n",
        "alexnet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training AlexNet Model...\")\n",
        "alexnet_history = alexnet_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "alexnet_model.save('alexnet_model.keras')\n",
        "\n",
        "# Evaluate AlexNet model\n",
        "alexnet_loss, alexnet_accuracy = alexnet_model.evaluate(test_generator)\n",
        "print(f\"AlexNet Test Loss: {alexnet_loss:.4f}\")\n",
        "print(f\"AlexNet Test Accuracy: {alexnet_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "px9_rWbvidHv",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ff90171-1d59-4032-e10b-f8d81e12c46e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training AlexNet Model...\n",
            "Epoch 1/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 537ms/step - accuracy: 0.5085 - loss: 6.0655 - val_accuracy: 0.5004 - val_loss: 0.6934\n",
            "Epoch 2/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 403ms/step - accuracy: 0.4954 - loss: 0.6934 - val_accuracy: 0.5004 - val_loss: 0.6931\n",
            "Epoch 3/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 399ms/step - accuracy: 0.4942 - loss: 0.6932 - val_accuracy: 0.5004 - val_loss: 0.6932\n",
            "Epoch 4/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 409ms/step - accuracy: 0.5008 - loss: 0.6932 - val_accuracy: 0.5004 - val_loss: 0.6932\n",
            "Epoch 5/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 395ms/step - accuracy: 0.4927 - loss: 0.6933 - val_accuracy: 0.5004 - val_loss: 0.6932\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 476ms/step - accuracy: 0.5091 - loss: 0.6931\n",
            "AlexNet Test Loss: 0.6932\n",
            "AlexNet Test Accuracy: 0.5004\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. VGGNet Model\n",
        "\n",
        "We train the VGGNet architecture, which uses deeper layers with small filters for improved accuracy.\n",
        "\n",
        "After training, its performance is tested on the Cat vs Dog dataset."
      ],
      "metadata": {
        "id": "azDajowTVySi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##-------------VGGNet Model--------------##\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "def create_vgg_model():\n",
        "    # Load pre-trained VGG16 base model\n",
        "    base_vgg = VGG16(input_shape=(*IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
        "    # Freeze the base layers\n",
        "    base_vgg.trainable = False\n",
        "\n",
        "    # Add custom layers for transfer learning\n",
        "    model = Sequential([\n",
        "        base_vgg,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "vgg_model = create_vgg_model()\n",
        "vgg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training VGGNet Model...\")\n",
        "vgg_history = vgg_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "vgg_model.save('vggnet_model.keras')\n",
        "\n",
        "# Evaluate VGGNet model\n",
        "vgg_loss, vgg_accuracy = vgg_model.evaluate(test_generator)\n",
        "print(f\"VGGNet Test Loss: {vgg_loss:.4f}\")\n",
        "print(f\"VGGNet Test Accuracy: {vgg_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "DltkBR5oidEU",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4282afc8-8d87-426a-d0fb-1e3a6d51762e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Training VGGNet Model...\n",
            "Epoch 1/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 1s/step - accuracy: 0.5659 - loss: 0.7136 - val_accuracy: 0.9022 - val_loss: 0.4407\n",
            "Epoch 2/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 872ms/step - accuracy: 0.8506 - loss: 0.4340 - val_accuracy: 0.9160 - val_loss: 0.3397\n",
            "Epoch 3/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 741ms/step - accuracy: 0.8800 - loss: 0.3550 - val_accuracy: 0.9259 - val_loss: 0.2888\n",
            "Epoch 4/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 739ms/step - accuracy: 0.8891 - loss: 0.3158 - val_accuracy: 0.9305 - val_loss: 0.2577\n",
            "Epoch 5/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 740ms/step - accuracy: 0.8995 - loss: 0.2860 - val_accuracy: 0.9341 - val_loss: 0.2364\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.9430 - loss: 0.2279\n",
            "VGGNet Test Loss: 0.2335\n",
            "VGGNet Test Accuracy: 0.9400\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. ResNet Model\n",
        "\n",
        "We implement the ResNet architecture, which introduces residual connections to train very deep networks.\n",
        "\n",
        "The model is trained on the Cat vs Dog dataset and evaluated on the test set."
      ],
      "metadata": {
        "id": "VfLUijKPVySj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##----------ResNet Model---------------##\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "def create_resnet_model():\n",
        "    # Load pre-trained ResNet50 base model\n",
        "    base_resnet = ResNet50(input_shape=(*IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
        "    # Freeze the base layers\n",
        "    base_resnet.trainable = False\n",
        "\n",
        "    # Add custom layers for transfer learning\n",
        "    model = Sequential([\n",
        "        base_resnet,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "resnet_model = create_resnet_model()\n",
        "resnet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training ResNet Model...\")\n",
        "resnet_history = resnet_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "resnet_model.save('resnet_model.keras')\n",
        "\n",
        "# Evaluate ResNet model\n",
        "resnet_loss, resnet_accuracy = resnet_model.evaluate(test_generator)\n",
        "print(f\"ResNet Test Loss: {resnet_loss:.4f}\")\n",
        "print(f\"ResNet Test Accuracy: {resnet_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "riRb74LbidBu",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94377fd3-f48c-4016-e6f8-9538ddfc1e62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "Training ResNet Model...\n",
            "Epoch 1/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 642ms/step - accuracy: 0.5627 - loss: 0.6993 - val_accuracy: 0.6435 - val_loss: 0.6358\n",
            "Epoch 2/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 465ms/step - accuracy: 0.6187 - loss: 0.6420 - val_accuracy: 0.6549 - val_loss: 0.6254\n",
            "Epoch 3/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 460ms/step - accuracy: 0.6419 - loss: 0.6304 - val_accuracy: 0.6655 - val_loss: 0.6171\n",
            "Epoch 4/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 466ms/step - accuracy: 0.6476 - loss: 0.6230 - val_accuracy: 0.6683 - val_loss: 0.6113\n",
            "Epoch 5/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 462ms/step - accuracy: 0.6534 - loss: 0.6204 - val_accuracy: 0.6629 - val_loss: 0.6125\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 708ms/step - accuracy: 0.6464 - loss: 0.6203\n",
            "ResNet Test Loss: 0.6213\n",
            "ResNet Test Accuracy: 0.6553\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performing Transfer Learning using the following models and check results\n",
        "# 1. LeNet\n",
        "# 2. AlexNet\n",
        "# 3. VGGNet\n",
        "# 4. ResNet"
      ],
      "metadata": {
        "id": "X6syerimVySj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. LeNet Transfer Learning\n"
      ],
      "metadata": {
        "id": "CYa-uMRHVySj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##----------LeNet Transfer Learning-------------##\n",
        "lenet_model = create_lenet_model()\n",
        "lenet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training LeNet Model...\")\n",
        "lenet_history = lenet_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "# Evaluate LeNet Model\n",
        "lenet_loss, lenet_accuracy = lenet_model.evaluate(test_generator)\n",
        "print(f\"LeNet Test Loss: {lenet_loss:.4f}\")\n",
        "print(f\"LeNet Test Accuracy: {lenet_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "kBo_p-adjSAe",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c928b552-fcd2-445e-c49d-c59dd49c65ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LeNet Model...\n",
            "Epoch 1/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 403ms/step - accuracy: 0.5302 - loss: 0.7907 - val_accuracy: 0.6661 - val_loss: 0.6016\n",
            "Epoch 2/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 395ms/step - accuracy: 0.7278 - loss: 0.5361 - val_accuracy: 0.7174 - val_loss: 0.5742\n",
            "Epoch 3/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 391ms/step - accuracy: 0.8081 - loss: 0.4159 - val_accuracy: 0.7401 - val_loss: 0.5382\n",
            "Epoch 4/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 397ms/step - accuracy: 0.8834 - loss: 0.2855 - val_accuracy: 0.7427 - val_loss: 0.6162\n",
            "Epoch 5/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 387ms/step - accuracy: 0.9429 - loss: 0.1588 - val_accuracy: 0.7423 - val_loss: 0.7650\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 319ms/step - accuracy: 0.7264 - loss: 0.7875\n",
            "LeNet Test Loss: 0.8063\n",
            "LeNet Test Accuracy: 0.7226\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. AlexNet Transfer Learning\n"
      ],
      "metadata": {
        "id": "sEStXAQGVySk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##-------------------AlexNet Transfer Learning-------------##\n",
        "alexnet_model = create_alexnet_model()\n",
        "alexnet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training AlexNet Model...\")\n",
        "alexnet_history = alexnet_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "# Evaluate AlexNet Model\n",
        "alexnet_loss, alexnet_accuracy = alexnet_model.evaluate(test_generator)\n",
        "print(f\"AlexNet Test Loss: {alexnet_loss:.4f}\")\n",
        "print(f\"AlexNet Test Accuracy: {alexnet_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "-2T10aPvjR85",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adefbbcb-8c9e-46c0-e669-fd9b86de31d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training AlexNet Model...\n",
            "Epoch 1/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 448ms/step - accuracy: 0.5357 - loss: 6.2273 - val_accuracy: 0.5635 - val_loss: 0.7132\n",
            "Epoch 2/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 405ms/step - accuracy: 0.5958 - loss: 0.6719 - val_accuracy: 0.6092 - val_loss: 0.6666\n",
            "Epoch 3/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 415ms/step - accuracy: 0.6452 - loss: 0.6266 - val_accuracy: 0.6707 - val_loss: 0.6015\n",
            "Epoch 4/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 470ms/step - accuracy: 0.6898 - loss: 0.5761 - val_accuracy: 0.7162 - val_loss: 0.5493\n",
            "Epoch 5/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 401ms/step - accuracy: 0.7418 - loss: 0.5252 - val_accuracy: 0.6882 - val_loss: 0.5757\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 317ms/step - accuracy: 0.6621 - loss: 0.5813\n",
            "AlexNet Test Loss: 0.5832\n",
            "AlexNet Test Accuracy: 0.6693\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. VGGNet Transfer Learning\n"
      ],
      "metadata": {
        "id": "BCv04VehVySl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##-----------------VGGNet Transfer Learning--------------##\n",
        "vgg_model = create_vgg_model()\n",
        "vgg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training VGGNet Model...\")\n",
        "vgg_history = vgg_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "# Evaluate VGGNet Model\n",
        "vgg_loss, vgg_accuracy = vgg_model.evaluate(test_generator)\n",
        "print(f\"VGGNet Test Loss: {vgg_loss:.4f}\")\n",
        "print(f\"VGGNet Test Accuracy: {vgg_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "thDLE0bfjR6V",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301b61b6-fed3-457e-b9be-f50b40f6ce4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training VGGNet Model...\n",
            "Epoch 1/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 765ms/step - accuracy: 0.6545 - loss: 0.6228 - val_accuracy: 0.8932 - val_loss: 0.4257\n",
            "Epoch 2/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 740ms/step - accuracy: 0.8463 - loss: 0.4188 - val_accuracy: 0.9136 - val_loss: 0.3330\n",
            "Epoch 3/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 740ms/step - accuracy: 0.8721 - loss: 0.3535 - val_accuracy: 0.9255 - val_loss: 0.2842\n",
            "Epoch 4/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 740ms/step - accuracy: 0.8907 - loss: 0.3074 - val_accuracy: 0.9295 - val_loss: 0.2541\n",
            "Epoch 5/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 740ms/step - accuracy: 0.8960 - loss: 0.2863 - val_accuracy: 0.9335 - val_loss: 0.2332\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 580ms/step - accuracy: 0.9431 - loss: 0.2241\n",
            "VGGNet Test Loss: 0.2305\n",
            "VGGNet Test Accuracy: 0.9380\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. ResNet Transfer Learning\n"
      ],
      "metadata": {
        "id": "dx_eEy0oVySm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##-------------------ResNet Transfer Learning------------------##\n",
        "resnet_model = create_resnet_model()\n",
        "resnet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training ResNet Model...\")\n",
        "resnet_history = resnet_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "# Evaluate ResNet Model\n",
        "resnet_loss, resnet_accuracy = resnet_model.evaluate(test_generator)\n",
        "print(f\"ResNet Test Loss: {resnet_loss:.4f}\")\n",
        "print(f\"ResNet Test Accuracy: {resnet_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "95EDtUDRjR38",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188c3738-0c97-4fc9-dfcf-49b99995357c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ResNet Model...\n",
            "Epoch 1/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 531ms/step - accuracy: 0.5403 - loss: 0.7417 - val_accuracy: 0.6395 - val_loss: 0.6388\n",
            "Epoch 2/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 455ms/step - accuracy: 0.6226 - loss: 0.6443 - val_accuracy: 0.6575 - val_loss: 0.6250\n",
            "Epoch 3/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 460ms/step - accuracy: 0.6439 - loss: 0.6289 - val_accuracy: 0.6641 - val_loss: 0.6171\n",
            "Epoch 4/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 461ms/step - accuracy: 0.6540 - loss: 0.6220 - val_accuracy: 0.6699 - val_loss: 0.6145\n",
            "Epoch 5/5\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 458ms/step - accuracy: 0.6604 - loss: 0.6168 - val_accuracy: 0.6792 - val_loss: 0.6070\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 449ms/step - accuracy: 0.6740 - loss: 0.6085\n",
            "ResNet Test Loss: 0.6143\n",
            "ResNet Test Accuracy: 0.6681\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Performance Comparison\n",
        "\n",
        "In this step, we compare the test loss and accuracy of all implemented models (LeNet, AlexNet, VGGNet, and ResNet) on the Cat vs Dog dataset to evaluate which architecture performs best."
      ],
      "metadata": {
        "id": "KZ6FnToFVySm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##-------------Compare Results-------------##\n",
        "print(\"Comparison of Model Performance:\")\n",
        "print(f\"LeNet   - Test Loss: {lenet_loss:.4f}, Test Accuracy: {lenet_accuracy:.4f}\")\n",
        "print(f\"AlexNet - Test Loss: {alexnet_loss:.4f}, Test Accuracy: {alexnet_accuracy:.4f}\")\n",
        "print(f\"VGGNet  - Test Loss: {vgg_loss:.4f}, Test Accuracy: {vgg_accuracy:.4f}\")\n",
        "print(f\"ResNet  - Test Loss: {resnet_loss:.4f}, Test Accuracy: {resnet_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "D7xrtqXjjR1c",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e5ebe6-7a65-41cf-df2d-bf1a240a123f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison of Model Performance:\n",
            "LeNet   - Test Loss: 0.8063, Test Accuracy: 0.7226\n",
            "AlexNet - Test Loss: 0.5832, Test Accuracy: 0.6693\n",
            "VGGNet  - Test Loss: 0.2305, Test Accuracy: 0.9380\n",
            "ResNet  - Test Loss: 0.6143, Test Accuracy: 0.6681\n"
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Comparison Verdict**  \n",
        "\n",
        "Among all tested models, **VGGNet achieved the best performance** with the highest accuracy (≈93.8%) and lowest test loss, making it the most effective architecture for the Cat vs Dog dataset.  \n",
        "**LeNet** performed moderately well (≈75% accuracy), while **ResNet underperformed** in this setup (≈66%), and **AlexNet struggled** to generalize (≈50%).  \n",
        "Overall, **VGGNet proves to be the most reliable model** for this task.\n"
      ],
      "metadata": {
        "id": "zizp4UajVySq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oSr5MTr1jRmn",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 14
    }
  ]
}